Random seed set globally to 42
Total trainable parameters:  19.935236 M
Epoch [1/20], UpdateStep [1/60], LR: 1.67e-05, Loss: 0.0234, Acc(token): 0.4527, α: 0.5
Epoch [1/20], UpdateStep [2/60], LR: 3.33e-05, Loss: 0.0209, Acc(token): 0.3200, α: 0.5
Saved checkpoint: ckpts/seval_qwen3_8b_sample/model_epoch_0.pt
Epoch [2/20], UpdateStep [3/60], LR: 5.00e-05, Loss: 0.0194, Acc(token): 0.4276, α: 0.5
Epoch [2/20], UpdateStep [4/60], LR: 5.00e-05, Loss: 0.0200, Acc(token): 0.4595, α: 0.5
Saved checkpoint: ckpts/seval_qwen3_8b_sample/model_epoch_1.pt
Epoch [3/20], UpdateStep [5/60], LR: 4.98e-05, Loss: 0.0165, Acc(token): 0.6444, α: 0.5
Epoch [3/20], UpdateStep [6/60], LR: 4.97e-05, Loss: 0.0174, Acc(token): 0.6561, α: 0.5
Saved checkpoint: ckpts/seval_qwen3_8b_sample/model_epoch_2.pt
Epoch [4/20], UpdateStep [7/60], LR: 4.94e-05, Loss: 0.0136, Acc(token): 0.8273, α: 0.5
Epoch [4/20], UpdateStep [8/60], LR: 4.91e-05, Loss: 0.0162, Acc(token): 0.6733, α: 0.5
Saved checkpoint: ckpts/seval_qwen3_8b_sample/model_epoch_3.pt
Epoch [5/20], UpdateStep [9/60], LR: 4.86e-05, Loss: 0.0142, Acc(token): 0.7375, α: 0.5
Epoch [5/20], UpdateStep [10/60], LR: 4.82e-05, Loss: 0.0102, Acc(token): 0.7956, α: 0.5
Saved checkpoint: ckpts/seval_qwen3_8b_sample/model_epoch_4.pt
